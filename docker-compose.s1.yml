version: '3.8'

services:
  s1-server:
    build:
      context: .
      dockerfile: ${DOCKERFILE_S1:-Dockerfile.s1}
      tags: ["${IMAGE_TAG_S1:-s1-server:latest}"]
    container_name: ${CONTAINER_NAME_S1:-s1-server}
    ports:
      - "${S1_SERVER_PORT:-8180}:8180"
    volumes:
      # Mount your Python source code for development (comment out for production)
      - ${SOURCE_CODE_PATH:-./system}:/app/system
      # Mount your ONNX models directory
      - ${MODELS_PATH:-./models}:/app/models:ro
      # Mount logs directory (optional)
      - ${LOGS_PATH:-./logs}:/app/logs
      - ./3rdparty:/app/3rdparty
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - PYTHONUNBUFFERED=${PYTHON_UNBUFFERED:-1}
    restart: ${RESTART_POLICY:-no}
    # GPU runtime requirements
    runtime: ${DOCKER_RUNTIME:-nvidia}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: ${GPU_COUNT:-1}
              capabilities: [gpu]
    # Override default command if needed
    entrypoint: ["python3", "system/single_server.py"]
    command: ["-m", "${S1_SERVER_MODEL_NAME:-ensemble-effnet-c5-lr-0.005-tin}", "-n", "${S1_SERVER_MODEL_PART:-1}", "-p", "${S1_SERVER_PORT:-8180}", "-s", "${HEAD_SERVER_ADDR:-localhost:8185}"] 